{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Patittaoliver/Missao-II/blob/main/C%C3%B3pia_de_Aula_ML_Pretalab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Classifica√ß√£o de imagem\n"
      ],
      "metadata": {
        "id": "nQdM-yFt3Nfz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xx-V5dVVzYBS"
      },
      "outputs": [],
      "source": [
        "!wget https://noticiapreta.com.br/wp-content/uploads/2022/03/IMG_6906-2048p.png"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classifica√ß√£o de imagem, como fazer?\n",
        "\n",
        "  **image-classification:** Queremos que ele classifique (diga o que √©) imagens\n",
        "\n",
        "  **google/vit-base-patch32-384:** Este √© o nome do \"c√©rebro\" que vai fazer o trabalho (um modelo chamado Vision Transformer)\n",
        "\n",
        "  **device=0:** Usa a placa de v√≠deo do computador para trabalhar mais r√°pido\n",
        "\n",
        " **vit-base-patch32-384:** Analisa em peda√ßos de 32x32 pixels (um pouco menos detalhado, mas mais r√°pido)"
      ],
      "metadata": {
        "id": "jwDvzt3NNPYj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use a pipeline as a high-level helper\n",
        "from transformers import pipeline\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "pipe = pipeline(\"image-classification\", model=\"google/vit-base-patch32-384\", device=0)"
      ],
      "metadata": {
        "id": "_IigwwKf5aOt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imagem = Image.open(\"IMG_6906-2048p.png\")\n",
        "res = pipe(imagem)\n",
        "\n",
        "res"
      ],
      "metadata": {
        "id": "h8G-eylD8-Qt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "*   {'label': 'peruca', 'score': 0.16841420531272888},\n",
        "*   {'label': 'estufa, viveiro, casa de vegeta√ß√£o', 'score': 0.035185057669878006},\n",
        "\n",
        "*   {'label': 'mai√¥ (roupa de banho)', 'score': 0.029690973460674286},\n",
        "*   {'label': 'camiseta, t-shirt', 'score': 0.027683282271027565},\n",
        "*   {'label': 'vaso (de planta)', 'score': 0.026298288255929947}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    "
      ],
      "metadata": {
        "id": "_eQZ-DNK-ddA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##An√°lise T√©cnica dos Pipelines de Vis√£o Computacional\n",
        "\n",
        "Pipeline de Detec√ß√£o de Objetos (facebook/detr-resnet-50)\n",
        "Arquitetura:\n",
        "\n",
        "    Modelo Base: DETR (Detection Transformer) - uma abordagem transformer para detec√ß√£o de objetos\n",
        "\n",
        "    Backbone: ResNet-50 - rede convolucional para extra√ß√£o de features\n",
        "\n",
        "    Mecanismo de Aten√ß√£o: Transformer encoder-decoder\n",
        "\n",
        "Funcionamento T√©cnico:\n",
        "\n",
        "  Pr√©-processamento:\n",
        "\n",
        "    Redimensionamento para resolu√ß√£o padr√£o (ex: 800px no lado maior)\n",
        "\n",
        "    Normaliza√ß√£o dos valores de pixel (m√©dia=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "\n",
        "  Extra√ß√£o de Features:\n",
        "\n",
        "    A ResNet-50 processa a imagem gerando um feature map de baixa resolu√ß√£o espacial mas alta dimensionalidade (2048 canais)\n",
        "\n",
        "  Transformer:\n",
        "\n",
        "    O encoder transforma os features em uma representa√ß√£o contextualizada\n",
        "\n",
        "    O decoder usa \"object queries\" para produzir um conjunto fixo de predi√ß√µes (100 por padr√£o)\n",
        "\n",
        "  Predi√ß√£o:\n",
        "\n",
        "    Sa√≠da √© um conjunto de triplas (class, bounding box, confidence score)\n",
        "\n",
        "    Fun√ß√£o de perdo: bipartite matching loss combinando classifica√ß√£o e regress√£o de bbox"
      ],
      "metadata": {
        "id": "pYhinFafelxm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pipeline de Classifica√ß√£o de Imagens (google/vit-base-patch16-224)\n",
        "Arquitetura:\n",
        "\n",
        "    Modelo: Vision Transformer (ViT)\n",
        "\n",
        "    Patch Size: 16x16 pixels\n",
        "\n",
        "    Input Resolution: 224x224 pixels\n",
        "\n",
        "Funcionamento T√©cnico:\n",
        "\n",
        "    Patch Embedding:\n",
        "\n",
        "        Divide a imagem em N patches de 16x16 (N = (224/16)¬≤ = 196)\n",
        "\n",
        "        Projeta cada patch para um espa√ßo latente de D=768 dimens√µes\n",
        "\n",
        "    Positional Encoding:\n",
        "\n",
        "        Adiciona informa√ß√£o posicional aos embeddings\n",
        "\n",
        "    Transformer Encoder:\n",
        "\n",
        "        12 camadas de self-attention\n",
        "\n",
        "        Hidden size: 768\n",
        "\n",
        "        MLP size: 3072\n",
        "\n",
        "        Heads de aten√ß√£o: 12\n",
        "\n",
        "    Classifica√ß√£o:\n",
        "\n",
        "        Usa o token [CLS] para predi√ß√£o\n",
        "\n",
        "        Camada linear final mapeia para espa√ßo de classes (1000 no ImageNet)"
      ],
      "metadata": {
        "id": "SfwWROVmfafY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pipeline para detec√ß√£o de objetos/pessoas + contexto\n",
        "detector = pipeline(\"object-detection\", model=\"facebook/detr-resnet-50\")\n",
        "classifier = pipeline(\"image-classification\", model=\"google/vit-base-patch16-224\")"
      ],
      "metadata": {
        "id": "JWujpyQ3-fbv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "detector = pipeline(\"object-detection\", model=\"facebook/detr-resnet-50\")\n",
        "\n",
        "    O que faz? Cria um \"detetive visual\" que identifica objetos e pessoas em fotos\n",
        "\n",
        "    Como funciona?\n",
        "\n",
        "        Analisa a imagem e desenha caixinhas em volta de tudo que encontra\n",
        "\n",
        "        Diz o que √© cada coisa (ex.: \"carro\", \"pessoa\", \"cachorro\")\n",
        "\n",
        "        Mostra a posi√ß√£o de cada objeto na foto\n",
        "\n",
        "    Modelo usado: facebook/detr-resnet-50 (criado pelo Facebook)\n",
        "\n",
        "        √â bom para encontrar v√°rios objetos de uma vez\n",
        "\n",
        "        Reconhece cerca de 80 tipos diferentes de coisas\n",
        "\n",
        "classifier = pipeline(\"image-classification\", model=\"google/vit-base-patch16-224\")\n",
        "    O que faz? Cria um \"especialista em fotos\" que tenta entender a imagem toda\n",
        "\n",
        "    Como funciona?\n",
        "\n",
        "        Olha a foto como um todo\n",
        "\n",
        "        Diz do que provavelmente se trata (ex.: \"praia\", \"festa\", \"retrato\")\n",
        "\n",
        "        D√° uma nota de 0 a 1 de quanto tem certeza\n",
        "\n",
        "    Modelo usado: google/vit-base-patch16-224 (criado pelo Google)\n",
        "\n",
        "        Divide a imagem em quadradinhos pequenos (16x16 pixels) para an√°lise\n",
        "\n",
        "        Reconhece mais de 1.000 categorias diferentes\n",
        "\n",
        "Como Seria Usar Isso Juntos?\n",
        "\n",
        "    Primeiro o detector encontra todos os objetos:\n",
        "\n",
        "        Ex.: [{\"label\":\"pessoa\",\"box\":[x1,y1,x2,y2],\"score\":0.98}, ...]\n",
        "\n",
        "    Depois o classifier analisa o contexto geral:\n",
        "\n",
        "        Ex.: [{\"label\":\"praia\",\"score\":0.92}, {\"label\":\"f√©rias\",\"score\":0.87}]"
      ],
      "metadata": {
        "id": "rI2O4nSTfl4M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Analisar imagem\n",
        "imagem = \"IMG_6906-2048p.png\"\n",
        "detections = detector(imagem)  # Detecta pessoas e objetos\n",
        "person_bbox = [d for d in detections if d['label'] == 'person'][0]  # Pega a pessoa principal"
      ],
      "metadata": {
        "id": "0wzJ9X0ZBYaE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "detections:\n",
        "\n",
        "    √â uma lista de dicion√°rios contendo todas as detec√ß√µes de objetos encontradas pelo modelo\n",
        "\n",
        "    Cada item tem a estrutura: {'label': classe, 'box': [coordenadas], 'score': confian√ßa}\n",
        "\n",
        "List Comprehension:\n",
        "\n",
        "    [d for d in detections if d['label'] == 'person'] cria uma nova lista contendo apenas as detec√ß√µes onde o 'label' √© 'person'\n",
        "\n",
        "√çndice [0]:\n",
        "\n",
        "    Seleciona o primeiro elemento da lista filtrada (a pessoa com maior confian√ßa, assumindo que as detec√ß√µes est√£o ordenadas por score)"
      ],
      "metadata": {
        "id": "IIs1oTcigYm2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Em modelos de detec√ß√£o de objetos como o **DETR ou YOLO,** **label** (etiqueta/rotulo em portugu√™s) refere-se √† classe/categoria que o modelo atribuiu a um objeto detectado na imagem. √â uma string que identifica o tipo de objeto reconhecido.\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "**Uma defini√ß√£o n√£o t√©cnica:**\n",
        "\n",
        "Imagine que voc√™ est√° olhando para uma foto cheia de coisas diferentes: pessoas, carros, √°rvores, animais etc. Um \"label\" √© como um \"nome\" ou \"etiqueta\" que o computador coloca em cada coisa que ele reconhece na imagem.\n",
        "Exemplo Pr√°tico:\n",
        "\n",
        "Se o computador v√™ uma foto sua com um cachorro, ele pode identificar e \"rotular\" as coisas assim:\n",
        "\n",
        "    \"person\" ‚Üí onde voc√™ est√° na foto\n",
        "\n",
        "    \"dog\" ‚Üí em cima do cachorro\n",
        "\n",
        "    \"chair\" ‚Üí em volta de uma cadeira que aparecer\n",
        "\n",
        "√â como se o computador dissesse:\n",
        "\"Ah, aqui tem uma pessoa, aqui um cachorro, e ali atr√°s uma cadeira.\""
      ],
      "metadata": {
        "id": "pSeag82ugxxo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result = classifier(\"IMG_6906-2048p.png\")  # Classifica a pessoa\n",
        "print(result)"
      ],
      "metadata": {
        "id": "5MD68KYrBTEV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = classifier(\"IMG_6906-2048p.png\")\n",
        "\n",
        "print(\"\\nüîç Resultados da Classifica√ß√£o:\")\n",
        "print(\"=\" * 40)\n",
        "for item in result:\n",
        "    print(f\"üè∑Ô∏è {item['label'].upper():<30} | üìä {item['score']*100:.2f}%\")\n",
        "print(\"=\" * 40)"
      ],
      "metadata": {
        "id": "lnDwyGDcDdgU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**O \\n** significa \"new line\" ou \"line-feed\", ou seja, \"nova linha\""
      ],
      "metadata": {
        "id": "Pb41qki2ksOB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "classifier(\"IMG_6906-2048p.png\")\n",
        "\n",
        "    Usa um modelo de IA pr√©-treinado (como o ViT ou ResNet) para analisar a imagem.\n",
        "\n",
        "    Retorna uma lista de dicion√°rios, onde cada um tem:\n",
        "\n",
        "        'label': Nome da classe detectada (ex.: 'dog').\n",
        "\n",
        "        'score': Confian√ßa do modelo (de 0 a 1, onde 1 = 100% certeza).\n",
        "\n",
        "Formata√ß√£o do Print\n",
        "\n",
        "    for item in result: Passa por cada item detectado.\n",
        "\n",
        "    item['label'].upper(): Transforma o r√≥tulo em MAI√öSCULAS (ex.: 'dog' ‚Üí 'DOG').\n",
        "\n",
        "    :<30: Alinha o texto √† esquerda com 30 espa√ßos (para organizar as colunas).\n",
        "\n",
        "    item['score']: Valor da confian√ßa (ex.: 0.98).\n",
        "\n",
        "    *100: Converte para porcentagem (ex.: 98.0).\n",
        "\n",
        "    :.2f:\n",
        "\n",
        "        .2 ‚Üí Mostra 2 casas decimais.\n",
        "\n",
        "        f ‚Üí Formata como float (n√∫mero decimal).\n",
        "\n",
        "        Exemplo: 0.9823 ‚Üí 98.23%."
      ],
      "metadata": {
        "id": "Ywv6cLVtjLpc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Voc√™ mostrou uma foto para um especialista em imagens e ele vai te dizer o que ele enxerga, com um \"n√≠vel de certeza\" para cada coisa. Esse c√≥digo faz isso:\n",
        "\n",
        "    Pergunta ao especialista: \"O que tem nessa foto?\" (classifier(\"IMG_6906-2048p.png\"))\n",
        "\n",
        "    Recebe a resposta: Uma lista com coisas que ele reconheceu e o quanto ele acredita estar certo (ex.: \"98% de chance de ser um cachorro\").\n",
        "\n",
        "    Mostra bonitinho no computador:\n",
        "\n",
        "        Cada coisa que ele achou vira uma linha com um r√≥tulo (ex.: CACHORRO) e uma porcentagem (ex.: 98.00%).\n",
        "\n",
        "        Usa s√≠mbolos (üè∑Ô∏è, üìä) e tracinhos (====) para ficar organizado."
      ],
      "metadata": {
        "id": "Bn_pxqO0jUHG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vamos treinar Imagens"
      ],
      "metadata": {
        "id": "-NcU49c2KSJB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torch torchvision matplotlib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "woxvV691EpXZ",
        "outputId": "fcda1241-6f7f-4442-f35c-a91936d4f541"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "path = \"/content/drive/MyDrive/Projeto ML/Dataset-img\"\n",
        "print(os.listdir(path))"
      ],
      "metadata": {
        "id": "yOfI3elZLIt1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**import os**\n",
        "\n",
        "    Explorar pastas do computador.\n",
        "\n",
        "    Criar/renomear/apagar arquivos.\n",
        "\n",
        "    Controlar o sistema operacional (Windows, Mac, Linux).\n",
        "\n",
        "√â como dar ao Python uma chave mestra para acessar tudo no seu computador!"
      ],
      "metadata": {
        "id": "Pr-8LmJRnFo7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "\n",
        "# 1. Primeiro, vamos organizar suas imagens na estrutura correta\n",
        "def organize_images(source_dir, target_dir, class_name):\n",
        "    os.makedirs(os.path.join(target_dir, class_name), exist_ok=True) #Cria a pasta de destino (se n√£o existir):\n",
        "\n",
        "    for img_file in os.listdir(source_dir): #Percorre todos os arquivos na pasta original:\n",
        "        if img_file.lower().endswith(('.png', '.jpg', '.jpeg', '.webp', '.avif')): #Verifica se √© imagem\n",
        "            src = os.path.join(source_dir, img_file) # Caminho original\n",
        "            dst = os.path.join(target_dir, class_name, img_file) # Caminho novo\n",
        "            shutil.copy(src, dst) # Copia (n√£o move)\n",
        "\n",
        "# Caminhos (ajuste conforme seu ambiente)\n",
        "source_dir_brancas = '/content/drive/MyDrive/Projeto ML/Dataset-img/mulher-branca'\n",
        "source_dir_pretas = '/content/drive/MyDrive/Projeto ML/Dataset-img/mulher-preta'\n",
        "target_dir = '/content/dataset_organizado'\n",
        "\n",
        "# Organizando as imagens\n",
        "\"\"\"\n",
        "source_dir_brancas\n",
        "\n",
        "O que √©?\n",
        "√â uma vari√°vel que armazena o caminho (path) do diret√≥rio onde est√£o armazenadas as imagens originais de mulheres brancas ou pretas.\n",
        "\n",
        "os.path.join()\n",
        "\n",
        "O que √©?\n",
        "√â uma fun√ß√£o do m√≥dulo os que combina partes de um caminho de forma correta para qualquer sistema operacional.\n",
        "\n",
        "target_dir\n",
        "\n",
        "O que √©?\n",
        "√â a vari√°vel que armazena o caminho do diret√≥rio principal onde as imagens organizadas ser√£o armazenadas.\n",
        "\"\"\"\n",
        "organize_images(source_dir_brancas, os.path.join(target_dir, 'treinamento'), 'brancas')\n",
        "\n",
        "# 2. Agora o treinamento\n",
        "IMG_SIZE = (224, 224)\n",
        "BATCH_SIZE = 8  # Reduzi porque tem poucas imagens\n",
        "EPOCHS = 15 # Uma passagem completa por todo o conjunto de treinamento.\n",
        "\n",
        "# Data augmentation\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255, # Normaliza os valores dos pixels para [0,1]\n",
        "    validation_split=0.2, # Reserva 20% dos dados para valida√ß√£o\n",
        "    rotation_range=20, # Rotaciona imagens aleatoriamente at√© 20 graus\n",
        "    width_shift_range=0.2, # Desloca imagem horizontalmente (20% da largura)\n",
        "    height_shift_range=0.2, # Desloca imagem verticalmente (20% da altura)\n",
        "    horizontal_flip=True # Inverte imagem horizontalmente aleatoriamente\n",
        ")\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    os.path.join(target_dir, 'treinamento'), # Pasta com imagens\n",
        "    target_size=IMG_SIZE,   # Redimensiona imagens\n",
        "    batch_size=BATCH_SIZE,  # N√∫mero de imagens por lote\n",
        "    class_mode='binary',  # Classifica√ß√£o bin√°ria\n",
        "    subset='training' # Usa parte de treino (80%)\n",
        ")\n",
        "\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    os.path.join(target_dir, 'treinamento'),\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary',\n",
        "    subset='validation'  # Usa parte de valida√ß√£o (20%)\n",
        ")\n",
        "\n",
        "# Modelo simples\n",
        "# Defini√ß√£o da arquitetura do modelo\n",
        "model = Sequential([\n",
        "    # Primeira camada convolucional\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3)),\n",
        "    MaxPooling2D(2, 2), # Redu√ß√£o de dimensionalidade\n",
        "    Conv2D(64, (3, 3), activation='relu'),  # Segunda camada convolucional\n",
        "    MaxPooling2D(2, 2),\n",
        "    Flatten(), # Prepara√ß√£o para camadas densas(Transforma matriz em vetor)\n",
        "    Dense(128, activation='relu'), # Camada densa (fully connected)\n",
        "    Dense(1, activation='sigmoid') # Camada de sa√≠da (classifica√ß√£o bin√°ria)\n",
        "])\n",
        "\n",
        "# Configura√ß√£o do processo de treinamento\n",
        "model.compile(\n",
        "    optimizer='adam',  # Otimizador eficiente\n",
        "    loss='binary_crossentropy', # Fun√ß√£o de perda para classifica√ß√£o bin√°ria\n",
        "    metrics=['accuracy'] # M√©trica a ser monitorada\n",
        ")\n",
        "\n",
        "# Treinamento\n",
        "history = model.fit(\n",
        "    train_generator, # Dados de treino\n",
        "    validation_data=validation_generator, # Dados de valida√ß√£o\n",
        "    epochs=EPOCHS # N√∫mero de √©pocas\n",
        ")\n",
        "\n",
        "\n",
        "# Salvar modelo\n",
        "model.save('modelo_classificacao_racial.h5')"
      ],
      "metadata": {
        "id": "u1lF9bsEJg-i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##import shutil\n",
        "\n",
        "**N√£o t√©cnico:**\n",
        "√â como uma \"tesoura e cola\" digital para manipular arquivos e pastas no computador.\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "**T√©cnico:**\n",
        "\n",
        "    M√≥dulo para opera√ß√µes de alto n√≠vel em arquivos\n",
        "\n",
        "    Fun√ß√µes √∫teis:\n",
        "\n",
        "        shutil.copy() - copia arquivos\n",
        "\n",
        "        shutil.move() - move arquivos\n",
        "\n",
        "        shutil.rmtree() - remove diret√≥rios recursivamente"
      ],
      "metadata": {
        "id": "65wL_rx8nnWm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##import tensorflow as tf\n",
        "\n",
        "**N√£o t√©cnico:**\n",
        "√â a \"caixa de ferramentas\" principal para intelig√™ncia artificial que vamos usar.\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "**T√©cnico:**\n",
        "\n",
        "    Biblioteca open-source para machine learning\n",
        "\n",
        "    Fornece:\n",
        "\n",
        "        Opera√ß√µes matem√°ticas aceleradas por GPU\n",
        "\n",
        "        Abstra√ß√µes para redes neurais\n",
        "\n",
        "        Suporte para treinamento distribu√≠do"
      ],
      "metadata": {
        "id": "d1dzUhjhn7Cq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "**N√£o t√©cnico:**\n",
        "Um \"assistente\" que prepara imagens para o treinamento, podendo at√© criar varia√ß√µes delas automaticamente.\n",
        "<br>\n",
        "<br>\n",
        "**T√©cnico:**\n",
        "\n",
        "    Gera batches de dados de imagem tensor com aumento de dados em tempo real\n",
        "\n",
        "    Funcionalidades:\n",
        "\n",
        "        Redimensionamento\n",
        "\n",
        "        Normaliza√ß√£o\n",
        "\n",
        "        Aumento de dados (data augmentation)\n",
        "\n",
        "        Fluxo de dados direto do disco"
      ],
      "metadata": {
        "id": "x44HnBkzoMSu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##from tensorflow.keras.models import Sequential\n",
        "\n",
        "**N√£o t√©cnico:**\n",
        "Permite criar modelos de IA como se estiv√©ssemos empilhando blocos de Lego.\n",
        "<br>\n",
        "<br>\n",
        "**T√©cnico:**\n",
        "\n",
        "    API sequencial para constru√ß√£o de modelos\n",
        "\n",
        "    Permite adicionar camadas uma ap√≥s a outra\n",
        "\n",
        "    Modelo linear de empilhamento de camadas"
      ],
      "metadata": {
        "id": "7Plu9RFeok6Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Importa√ß√µes de Camadas\n",
        "\n",
        "**N√£o t√©cnico:**\n",
        "Diferentes \"ferramentas de constru√ß√£o\" para nossa rede neural.\n",
        "<br>\n",
        "<br>\n",
        "**T√©cnico:**\n",
        "\n",
        "    Conv2D: Camada convolucional para extrair caracter√≠sticas de imagens\n",
        "\n",
        "        Filtros que detectam padr√µes locais\n",
        "\n",
        "    MaxPooling2D: Reduz a dimensionalidade espacial\n",
        "\n",
        "        Mant√©m caracter√≠sticas importantes\n",
        "\n",
        "    Flatten: Transforma dados 2D em 1D\n",
        "\n",
        "        Prepara para camadas densas\n",
        "\n",
        "    Dense: Camada totalmente conectada\n",
        "\n",
        "        Para classifica√ß√£o final"
      ],
      "metadata": {
        "id": "yw49FV6KoydA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**os.makedirs()**\n",
        "\n",
        "O que faz?\n",
        "Cria uma pasta (diret√≥rio) no caminho especificado, incluindo subpastas necess√°rias (caso n√£o existam).\n",
        "\n",
        "Par√¢metros:\n",
        "\n",
        "    **os**.path.join(): Combina partes do caminho (ex: \"dados/train\" + \"cachorros\" ‚Üí \"dados/train/cachorros\").\n",
        "\n",
        "    exist_ok=True: Evita erros se a pasta j√° existir (ignora silenciosamente).\n",
        "\n",
        "Exemplo:\n",
        "Se target_dir = \"dados\" e class_name = \"cachorros\""
      ],
      "metadata": {
        "id": "M0zGE3JGqmTg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**os.listdir()**\n",
        "\n",
        "O que faz?\n",
        "Lista todos os arquivos e pastas dentro de um diret√≥rio (source_dir).\n",
        "\n",
        "Retorno:\n",
        "Uma lista com nomes de arquivos (ex: [\"img1.jpg\", \"img2.png\", \"notas.txt\"])."
      ],
      "metadata": {
        "id": "9K8u4Riiq0yQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**str.lower() e str.endswith()**\n",
        "\n",
        "O que faz?\n",
        "\n",
        "    img_file.lower(): Converte o nome do arquivo para min√∫sculas (ex: \"IMG.JPG\" ‚Üí \"img.jpg\").\n",
        "\n",
        "    .endswith(): Verifica se o arquivo termina com alguma das extens√µes listadas.\n",
        "\n",
        "Por qu√™?\n",
        "Garante que extens√µes como .JPG ou .jpg sejam tratadas igualmente."
      ],
      "metadata": {
        "id": "a1upoNKLq9ra"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**os.path.join()**\n",
        "\n",
        "O que faz?\n",
        "Combina partes de um caminho de forma correta para o sistema operacional (Windows/Linux/Mac)."
      ],
      "metadata": {
        "id": "_KcOiBVxrIib"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**shutil.copy()**\n",
        "\n",
        "O que faz?\n",
        "Copia o arquivo de src (origem) para dst (destino) sem alterar o original.\n",
        "\n",
        "Diferen√ßa para shutil.move():\n",
        "\n",
        "    copy(): Cria uma c√≥pia (original permanece).\n",
        "\n",
        "    move(): Corta e cola (original √© removido)."
      ],
      "metadata": {
        "id": "1c49efnxrQLj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Captura de tela 2025-05-07 184707.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAgsAAAC9CAYAAAA9Uz6PAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAADsMAAA7DAcdvqGQAAD91SURBVHhe7Z0JXBbV+sd/mWmWlgug3LLF1AQVV2y7XRUtvYpkZYWUilmZWSa03jJMsjJNSMtrdsvUCsnr3wzF3CBbNBPLpYLc6uaGCmq5VFrZ/5yZM+87M8w77wsvmODv22finXNmzpzznO05z3NmPCMisvWfIIQQQgjxQTX1lxBCCCHEESoLhBBCCHGFygIhhBBCXKGyQAghhBBXqCwQQgghxBUqC4QQQghxhcoCIYQQQlyhskAIIYQQV6gsEEIIIcQVKguEEEIIcYXKAiGEEEJcCUxZiB2HJXmrsdZzfIpPFv4Hj/S8WF0QDA3Rd/wCrPxMpDnrAbRXoeQkoup3yfjeKiAwGnYfiemLPsYa2Sayn0UPPIC35G9Rj6Wm3WOYI9rA6s9m44l2KqwciB07X6Q5H8/GqoC/nN6YsNjcl+zHDDyoriwNp145T3f6YVKOqM/PRX02VEEmhrz2sajr5XilvwpwRLWVxeNQrtX64Axbm7MennGgYRwmZH+K5a/dFdi4HDkM01d8io+mD0OkCiJVh1JZFo5sWobMzDmY/+E2/NKgNW4bk4YxXVRkGWn/4AtIavkNJvQfj9UNbsPY8XFCfahArr4PU95bgpVvlmFCIyauwn33xyOqwc/IXyzaRN5OFV4G5KCU2hk/ijq5L/MYeowdh77l1Aga1K2DatXOxJnq/K/ne3wyf47Wj+Tx+W4ZVojP1Xlm5lKs164rHadeOcvOrSmzkf3xfEyo1IrPXKz86pAYYZujY7y9MQ/GFS1rAIc24uPZKuhksn6pp/1lLt2MIyLIGNvlMf/T7/U+Of1RtPzuVTx6z+v4Ur/Tnbp1cV7N6qh2hjonVYrA/tVJufIcLbSCD59Bj0eztaCG97yGeXdH4YgprFKgytKg4B10HPiyCjzNcahf/8hVz1PoihV4uufjWKiFScvC7YigbAPmwVmrMSDiW7wVnYhJKux0R5fJfnw4pjce0RtW5eSWNOQ+ejVqbngdN931OvaqYPSfhBXJV+DEyhcRM3KuCnTCqY+VM2Xq++R0pMx7Fva+n48fxN8GjZqI/0ci4emZyF6hTNKff4wPpo9Ed49CrczT70zAmHeXYbX4/Za0tXZ+AK++9wE++Uw3f63OycCEAYYN2jDBTcB9yf/BBytX6elOvQvthdZrpLP2s2V461/dTNaIhrgycRzm5Hyqpblm5RLMGX+HbkaT5jepKMjfEbdr8Vo+fOXPSGu5t1w576Xjvisr1PZxCmC4E57AwPEZyJX1Y8heRmtuCzGISUE26IKnxbWOLgztOlucQ9glPZO97ozPPkS2ue0ok+lbo+7ABFU3a1YuxKv3WH0V7QeMwdsLP9TbhHSTZfwLV4vw2PHZ4jzbu0p1bXN2HNqgSDv33RSr5eOSHnhk+vveND9+H28/dRMuUdGlw3jmyxg7dSFWfm7IyqVdC+zlNM7ThnldRbKsY0wZ7/zgFMxf4pVZ7rvjMNAjCoc2IPranKfj0LDdXXhVpblm5TxMMsuv4RUYbFyftworl/vp0xZ56vEDIuTvBug6Wl5rmOArYV/87ypI40LNiA4WN0LC1S1RG4fw1UqhKJSqPQqUfHM02entYP6ke+EVg6/2U1qM+lcWWKMfJlvHXnMbLHGPQLoqX5WWXJEPvT28hEEqTuv35j67cCZS+pWHa5tUBGXf4HjVBQgRfw4USZXhUkS1PA87PpmBcUkvYNb6n9CgdTwevL+zdqmH5lcgIv9FxEdfiQFyGdU2Ck2ObEDWK6Mx6qUl+OGsJuh67zDcY+7/9a7BbX8/jJXzluHrQ9UR2vFOpL/7IK75eRXmzl+F7b/VQUTfOzFIOckihz+HCcP/gfrbFyH9qRfwdt4hhHe9D6OfFnmR5jdldsPuPM3ktsRs87XlT0+rCy76YxOWaia7Lfjzb1fhzvFPY8gpPEaVG5ddh1tDt2DR3Cys3PWHJvvHHhWC/m4l5mcuwybNfrlZk41muiwLsc/i32NuRbNf1+Lt50cjPfs71GwZj9HPDDYpgECT6/shdPMHWp3v/CMEHYc8DJkVScO+4zD2/h5oXvtHrF8sTak52PJHLdTXo60E0ubs1LkCN2ltcC4Wf30EtZv0woh/9VORvTFuymjc1rI29n6eJZ6dhc+Lz0OLuIcxSba5stIgGtF//hcPxV2prfhc27VP6uCKm67B4ZXzMWfxNzhSuwl6P/AYblWxbdtciiMbFuDlp4TcF/+As5p0wdDhd1nkjst74Q7ZBhbqfa1J7yTMSe+PsM2LtTQPVf8brkkcoNKMxPBx4zC8c31sz56EUc+/g7WHwtH1/lFWd6VPeeouGt01cwSbloq6nL8S34mzytkXlSuiRktcMUQFIR5Xt6oNHPoaK/8rTkvVHpV8u16EP5TbYOnmP/G3qxMxwdZf7O2nvLik771oXfgh5mYuwcZDtdBEtEFtTHCi3QN4MSUeHRv9ge8/kn1jIdYerCYUJYHq961q78Pn0i03fw2KzrsccY8E79omFUOZlIWGEbfh+cQrxGB8CAWrs0RINh6/5Ubc+9R0zPv0PUxOycFWERp+cZR2vYf9qzBrzBL8T51i0t24fsDjmPDOEix+ZzRm5x0UHesCNItW8RrfI3tUMsZOHI3E6XliCKmGcw99irGDR+PFZ5MxS95T7VJEdpXXdkZCj5aoVbhMxD+HdxaLvIx8C3kHquGCtp1x9UcZePGz3TgmL/1pM16cmIa3P5InCkv+VFrHN2L6wLsxSlz74lND8Oj873GiVjv0uPM02MLz6zrMknKe+BwenP459gvZX9j0CiB/AaZOXI3dUpDHdmOVkM3UrHz9nlLREPf0vRZhv2/EW8OSMXneErwz9gksEo2nVstOltXYsS/fRuJTog5EnU9fvV/UeWM0vUrGXIX7ErsgTLST+UmyDYprRFu5c0CKs9k2oDZno/oOLNXaYBpGPZ6NTSeA8y6J1CwXDe+5AdeGVUPh0lT0G/mcLqth07D6kGhznW9Cgp5C6TnxLRaNmYnVmu3aT7vWbnCiOnYuG40Hn5Vt9wks0DJ+MVqqGybdKRSBR9NEekLuT70r0hOr4AubwiKKI2vwuuproz6QCmEtVN86G8NkWUWasq5wXjO07yH+drkNPVvVErJ4HoljZ2PxvCl4cNZaHKh2Adp20SpLx6c885H1aho2/yQvOobdn4l8v7pAhFbevjhn5ddilKyB5m3j9YBbOiFSzJb7v8jBHHlemvao5HtswwwMuFP2SyG/wf/C/O9PoFa76zHELAZL+yk/ftswS6972ceS5mPbiWq4rGMfxw2NQ4bdgohah7B68mDRzlTfuGUEphj9vtoeLH36Nr19ivY1bOrnOCTaSueblazIKUWplIUGXZ/STFHZs5Jw3QV/iNXDK3hOasei8q+87QlMfnsuluYuE6uDeDTX7rCxb5d1AL+kB0aM/zfmLFyGD1d8jCf+UU9FmDi4A/nGPHT4F22iP/JDAVboIZi/XfaGajizujyLwsXh4k94D7yombbk8QT+IZeYZ5/jvNI0Y8mfSmvbV3jN1OG+/OoHiO6M8+tdqgdUZXZ9rw9okoW7sE/8qXm2ti4oJzqi2YU1xOAYhXsWGvX1PhJk46lRS1+BKHZ97/XtLtxVJP5fA7W0CzqiyQXiz9bP8cY6ee6HQNqcHXMb3Psd9sgGoNpTdNMLUFOoUd9+btI692Ziyy7xt/b5CNVDSs/BPdjmaXdlbdcHsd2bcWzTM45z1A2X9ByOCa/ORrbosx+tfFxPz46pDeT/rKnZ2LVtlfK/78XmXUJxk/3vLPGnzcXQstnzBZVHcTx5rZa/s42HSlzk6Uwl7ovKFVG71VWa4hgbfTnOE+1l48dqtV+a9qjk+91Xpv0PWIeN/5NSOA/1pEfYwNJ+yo9dWzO9z84vwHbt0fVgfrROb7S4SPTtAxuwfLY9I6rf7/8Wq42BXLB39lbo3abMvYZUIGV6GyIz8zWkDozHTU9naQ2n4ZCnMeHhOLQ7Zzs+/r/pePaRLGzRb3GhM8a8NBoDOzfBz+s+wDuT/4V/fyZbnn+O/XJY/fLBliyMTHrIeoyegTwVTU4xDqzGK/b6SkrH+yo6IP74wzSA+qLsbe6UoDzbdZcUTBozAJ0v+xnrsmdj0mOv4rMDKs4Px352tyJtmW/LozhS3lyrYk83lCuidgSuuKU3Okc1AArXIltblVTy9ogzcaa/Nx/+/AO/q5+kclMqZeHY7tWa6evFidORVeAdmmOvaIlaQltePT0ZY6fMxuLqNS2rQkeu7oy2F4jHb8rWzMuvz9uKGuecqyLLililyIXOxZcgcstKfPqp6fj82wAmEzMqrctaW/yH7VtfjHo4gR+Ly+ijPw2pWauO+iXk17aJvsFUYy127jsB1L8ETavb6uvTDV53lStGPXXAg/6s0RXQ5vJ2FYnW0AAtrjDtHWgYj2bS2nHoAAr1kCApz3atc3WXNtBEsXAIRon+PG9LDZwTrNFo2x4xCgAXXRqBLeY8iuNz03hReip3X5yz/Eshl/PQos8t0HSFDbm6ZbS07VHJt0lr876Sdoi6pB5w4kcUyc0dFUzdEFM779IBzeqLR+/b5aCwqr7doDU6m/2JGkZcC1xp2p/QsH9T6N2mfHoNKV9KpSz4Yu+PcqVfDy37JOP+4U/gtYfMbyf4YNtBHBLtBZdcifHD78P9L6Th9taaLyEIspG9ehdO1IjCnbP+g7HD78Rdw4UCM/U9TBmuLsnbBdlOtec+9DweNbbmliAbsz/4Fr8YaT2UjIefeQPj+14K7PsYs2e6r66IYOE3+P4XsajqlIgZz0j5/QfjujfS94xo7EXmRxvwCxrh+qffxaQnRX3dlYxR42fi7bGB7uA26qkFbp/0FiY8KZ7z0BhMfyu15IdsKqDN7c2ch49Egwq/PgVzX3pCPPsJTJo6FFee9wsKst7yunGCIoB2XUq2HTwsplkhiqueF332Poyf1B9Bd7+FH2D1rhOo2SYRb00fg/vvuhP3i7p49f3JKE02t2magRxPnsCop4ehR2Xviws/wUZRpAYRLYRauQcbcpTLqrTtceG7WFTwi0e+Dws5jH3zeWhi+OhdnAwxNOz+mN6XRb3OePI6hOMQ1nwwx0FhFX173sdirG2Aro/Ox6vaPaJv/Fe2BSPO6Pci7sk0TB12Bc775Vu8P9PtdVLyV1EuysLCidOQ/d1R1G9/KwYmXI0TCxZhk4rzyd6Xkf7GFyg681LEJCbgpks24f1PgzfBrXg6GeOzNmF/rQj0TLwH9w7si2sbF2Pz1+qCvXPwfx98h0NnXYaYW69Bs7NVuANfTnoMY2Z/gT3VRVrxtyK+exMc27xAdOzHMT+YhdJpw1t47T+rsONYbbTq2Q83dgAWv/u5/jaKYu8bT+ORNz/D7t/DcVVfUV9Db0KPNmdh5zeBrxaNetpd7VJ07Svqqd8/0PDXPShhVa+INrc3C4+M+jcWb/4F4VfFIT4+Fh3P249Vbz6OhycFsokiMPy261Kyd9IkvL62GNUu7YrEO27EJd8uQPDd7yOMHvkisr7dj1oRPZA49B4MvOnvaLx/C0qTzYWz38Paot8R0j4Ose3CtLDK3Rez8ZHUFiSFG7Dc8NOXuj2uw6RHxiJj7R5UF/KNF3LoftkxbM56Efc9qruEK5pN2fPwa4e+uDW+B1rULMLaN5/CMyX2JOjsnf84Rr2yBN8eqY/2PUWd3doTrar/BLnjyIjb/LPs9yIuriPO3/8Zpj/6GMqx25ByJLCPMhFCCDl9kd9ZuKMFCt5Wr72T045ysSwQQgghpOpCZYEQQgghrtANQQghhBBXaFkghBBCiCtUFgghhBDiCpUFQgghhLhCZYEQQgghrlBZIIQQQogrVBYIIYQQ4gqVBUIIIYS4QmWBEEIIIa5QWSCEEEKIK1QWCCGEEOIKlQVCCCGEuEJlgRBCCCGuUFkghBBCiCsB/auTdw4eqH4RQgghpLIw/c1Z6ldw8J+oJoQQQogrdEMQQgghxBUqC4QQQghxhcoCIYQQQlyhskAIIYQQV6gsEEIIIcQVKguEEEIIcYXKAiGEEEJcobJACCGEEFeoLBBCCCHEFSoLhBBCCHGFygIhhBBCXKGyQAghhBBXAv6HpM46qzrq1D4XNWrUwBlnqMDTlD+FxI4fP47DR47it99+V6GEEEJI1SQgy4JUFBrUr4eaNakoSKQMpCykTKRsCCGEkKpMQMqCtChQSSiJlImUDSGEEFKVCUhZkK4H4gxlQwghpKoTkLJAq4JvKBtCCCFVHb4NQUwkI2P9RqwzHcvS4lRceRGHicu96fZJyxXPycVEt8ckZWLd8nT0UaelR39mRpI6rYRocgpKBl5Oiszj0rFsfSYqscjLBylHt/7kL95EQPVmxl/aWh1549dlJKsIB1Raf0UfSsow5dGx/NZxq6QM/cW74Ld+KvDZpxhlVhZCm3VAdKcrbUcrNNZj0bS9PO+ApqFagOf6lvoFOo2vxo2Dh2Po4H64ppm6sBSENvuHfn9CrDVdXISWJfJ2JdppzzDy5iveV9m88VUSrVMkAjOj0K6tccxAUczYcpuknFiQHCOeE4OHslQAqXAo85OFmCh6FyLF1p+8E66/eDPJ6B8Ton4Hgr+0hQI9IhyLPPGjkBuW6GMyE9f2jlS/TzJiXOq1Z5TKozhm7kNMqlkJlQuBRITmGtfo5fSWw1+8GwHIsMKefeoR0KuT4Y1KTpLdU/6L5KvrqzODzfi/nsPwBq7HqNmP4ep6x/H1zH/i0dmX4/7X/o1eFwFb53bDiNfFhNwzBS/e3xmh1X7H76gu/vsZm+Y9iaTXN6q03AhFjycnY/i1Yah2/Ff8Xv1s1DhxEBszU/H42/L+oZi8+FY01S/2cHDVC7g9FSpvKtDE/k+exYBnc32Uzbh/qTrzUrinSP2qpMgVRmo3FAlFISFdhXmQmrHe4K9LLo/ZRXagsYjaWIr0pCIjO233JCxQQaVDf2Z4tlP5KgdyVZkatSEIGZSSYGWutSk5GcWjkoq8QtDqsdFCtEtIUyFWfMXL1XUv5AORYdiYUjZFz9+zfdW5ft8+FEQKhcFxjDiZ2PqyU57NYf7iVVCgWGR4kp/9V1Nmy8Ly1FvQq2c3pK06IM6kktBNnEtFwUwNNG9/B9C8F1oJRcFD6B145N7OaFCUg+cH9UDcoMewZOfZuDx2EG5Rl7gSfSduE4rC4bxJGBbXG33l/bvPR1Q/4/5pGKHlZw62ijM5ycu86hP9UoztL+OMIwn/t+VX4NfNWJGVq92tY5TJezgpClWBPl3aIKQ4B7MdB4E0zM4tRkhUV926oJku7aZAqVCYw2SH9pre1rmZo2XnscdrYS73+jWfWp+/LM2uNgpsafjU9h3Lq6dv3CMHECMdn2Zip3JqcjOZdi3l9m/ytZpnna7X0/dcY1iIKkLmlnghg8tUuJlAZU6siLoZGJaDyZmFKkBHb3fmutLru1zlKupsRMw+zEpYowL8YG8nFqukrb1r6H3JX1v3RZ/GYcC+HdaJd1shikPCtcWiv3itD5nzqPIfSH6CfXZlo0L3LBwsFI27SWvc3rM1Ltq3F/tUOLp3QPOzjyN/6XP4RC7Ki9Yi463peH/J1/ipuX6JK3XPQU3x53DRJuyQ5+L+D/4vI/D7TTQffA96N6uG7z6Yije+UoGnGU0bhaB444c+Nd0FKzaUroHHdUX4Rq/pcFZ+JAa6+UPNyElrUBhyUwzT3xpED7KaQPt0CRerKyN+hljxJJo6t77yiNk3Q8VHYTJiYbHgygEhtY0lDat50UTWh9hYHIKoLqYBWJQvKiQfi6RlROQ3VQ6m6lntZm5QF9lIX4MCRCLa/IykTogwlDSt3PCmk5KD0EE+FA81wA6Et4z69eZBTg7MZhOoqAdfRrtgZa7JU7dM6fEvAb27wWI0L43Mqyxx6BIl+toeuYRxwile1KOsm8klV6ILkl9CbnEkenmU1lhE5M/wYbHz92zRDKJFnVsmN9HORsh6jUdAxgTZjix1LNrcvm5ILU83ptb3ilG4TT9dsEPMKmGNHdIPw4VCLP7i0xNEWw7phv6qHSbFdwNEn3G2nlhlGOyzKxsVqiycsXMTtp51OWKvaYyDW7fgkApvHno+auAIDhWrAEHRJ7MxbeqbWLpZBbixbCW+Lj6Bi3q+iDdfeBg3/r05Di55M/D7DZoPwbAbIlBt2wK8Os0+kp6HJsOGY6hxDPwnSqmHVBLicKFQgP1TigaelYQE04CVnpfvo9PYEYNT70gU575kMrOmIWGmuN/EguR4S7xMPrSxylxSglAM8sVKyGtq1QdVdSLQBwTrM6T1JCLaSaHJwoqNJsuKQLPE5K/xDqDFhZoFSyM9yYeJWM+n+RlycNaVNL3cBeZBWchwUb5NSTFwKKO8frKpDE4TR3qyk+kzeJlLeYaIZ3kH2Cw8NDkHJpGXUuZVk6QMocQiB5MdJ3Pn+KQMqfCZ5WZGlzNiEpAklIr+MULEmc4uBn/PllaKgZHWNtUnbaSmdAfmdnBqR8Zk3AZOzbj0CMVJKKWWdiSVcDHZj/BYU3QFx6Oo+otXbT2it1BohELbS8hAWwQ4UEKGQT+7clGhykLduvtR8MO5OP/8H1Hw2W4VClxUt476JemLpPSXkaYdzyIxWgW7shTPJ41F5hf7cG7Lf+LuUVPxxuyJGNS+NBsQQ9H/7ptweY0fsPzVf+NrFeolBBHdrkc34/hHG/xNxZye7MNO5z7kjFxlGKZI2yrVN00RLnpS0Q7/DzKb4AeaktdMf+bJuwS6chQiVrWe/IkjVZoefCg0umXFGPD01UVBnhpU1YCQKtLwt0rWlKbITspsnIzoyGJsXCHLqpc7YpA3P/KQ5QppVNKe46uM3pWM/1Wkl2BlrsvT/Vmll3nVQkwS0hIUluPDV+0cr03g8GUpUGhKZSQGalYkJ6XC37P1etWtYyZlVVrM5B4ZX/sbSuCrHW1FYXEIwp3cUqVBcw847Z0Sk32KVJiMtiX3MwgFxTNe+YsXpGcgF6IPa9YxJyuKLxmWw7MrERWqLAB/4JNvf8CJg/lYvUwFCTbslfscbJzfGC0imuPCuurcH0UfYdZTQ3Br7GCkvpaDXbXa4rZ/JSFWRfsjtP8TuKV1DWxf/BJecXQ/fIfsfjfgVuO4axxWqJiqRcmVsx19T4PbBGxFm1TMJnXbKtUdr4nRGd3vaTbBz7Inb/cTOlBsMs97Dl+bjpQrQhvwlAsizzOiiAFB3qvcAI7+fgOpWBgWGs0FsQGarqAosLyJog5fg3UAZQxEAdAJXuaBPKtUMq8ySNnpG3qdy+orXr39EJmoJhpxiMksRPwXk2rdl7B1j9mGY8bfs9UkqNWreZIU4b2lpqorwfrzExEhYjSF1qdL0V87KiMm94aj4iQUputMbSphW2OEmscrf/FiDNwp9Gxn/Mgw6GdXHipYWQA2zxmPp8a+geXqXFK0ez8Ooy4uaH65OJuP9KQHkLzKunnHjS6PzMCcuVMwVPMLbMfqec9hykc7gTqXoXUX7RJ3Qm/GgzdFoUbhcsycHMjbF1UbfeXs9dtZ0Qctz56GrB0o8e5HnOgA6qe8Xq6Yc1MC9HNa0FchdtO7tpI2UH5+XysebXXtWb0b6KseHX1gcFqx+0ZXqKTJXCpOyM0oWTY1KMj9GYYPuSTSfK+XT7ogCrKNwUeW2+RK8YNzGZWcNCVCL2NgJv5gZe7jWZeFm8ytZZF5VUBOxvrryL72EfiOV0qo+RAKabH4T+4t8VwvVtwjpFVAW8FKd4SBv2dLpV5NgiXqNQsPdbc9W+5TETGaQuvYDpzbkd73DCVCb+dWzH3TAWlR0BYegb8Borm8XPZglYgXyohmNTDcESo4EBnaKfWzKxFlVhaMbxHUrymTqI7a2rcIjO8smCjajHXfbFcnigXZWCN0g4uvewQP9pL3dUNCU7cWY2XF+h/wW+0WiHngfvSSz+06APEd/gb8uhv/+0ZeYXxnoTbOFGdn1Gxg+k5CKPqOHID2dfZj7YKP8Lt2nTpaml/ZMMrkParsdxbERKf5uy0b5CRSqxYrCovvWx8UYuKNyUF0KIsfzj5oiDQCdkMoK4d50NMGQ1Pb0HYTm3ygsqObk9dW79YJW/p95arIID1TDLqWTZECkY6bG2FB8kIURMZiRJTo6yZzQJ+0TMtbIP72f8hnI2qk5hv1WifE4JydL8o90rKh0Zq2CWk2LbZtGtXk5PVZO5UxKc1po1nwMtfdK7GmvJas87LIvNIj95bA11tGAn/xftH7nqa8ij6suSOMNuEvbVHHbv750uPchrW+l79QTfRKsTRNyPa+aUff6+KgnPvA2Hvhq1wl4/W2qinuyh3h2WNQyvop/bMrFxX7nYXiOej1wDQVp3/7AOo7C2g9COMej0erBjU0jeXE8f3Y9ME0vDQ1R3/DwQ+t+o3B8PgrcXFt/V99/P3I//DpjDEYv1AqJmX7zgK26Pk97b6zYCC1eM3UaUMoC5bVhOU6udJZiPDUWBQa739b4vMxayYwsLfxbrHU1vUVjaaAiAlDd1l4LRGyU2n+bIlc0WaHI9Vzvy1e5G0WErUPt3gVGqXkqLOCmaNQ2Nv0brZEe65pQpPPcTTVepHulRJ+S1s60tTuvgrRy6+9rWFboVnKJTHJXYuzfGdBpeO5XNaDbfVlr08jvYqQuUUOos5TCtHL/p2FMsi8UmMvrwdVV5f5ibc3I60+pTlejyvZHvV2r/n1dyS4py1qxbGvC6T1oOSmRj1tv99ZsJfZPnYE0jdNaGV0LIZRbls/KNGm3OId+qLqM9o3Z+CvfoJ5duWjzMpCudG4FdqdvRfrtpgnXOfJHgc/RVr/0RaXhrRwXIjttvtPLlVGWXDE1LkreWMnhBBSNv56ZcER6Ub4G85RZx5+P4D/fbm5pM/8L6ZqKwuEEEJOd05RZaFyQWWBEEJIVSagDY5/+lUnTl8oG0IIIVWdgJSF48ePq1/EDmVDCCGkqhOQsnD4yFGuoB2QMpGyIYQQQqoyASkLv/32O/YfOIhjx45TaRBIGUhZSJlI2RBCCCFVmYA2OBJCCCHk9CUgywIhhBBCTl+oLBBCCCHEFSoLhBBCCHGFygIhhBBCXKGyQAghhBBXqCwQQgghxBUqC4QQQghxhcoCIYQQQlyhskAIIYQQVwL6gmNEi2bqFyGEEEIqCwXfblG/goOfeyaEEEKIK3RDEEIIIcQVKguEEEIIcYXKAiGEEEJcobJACCGEEFeoLBBCCCHEFSoLhBBCCHGFygIhhBBCXKGyQAghhBBXqCwQQgghxBUqC4QQQghxhcoCIYQQQlyhskAIIYQQVwL+h6TOOqs66tQ+FzVq1MAZZ6hAUib+FBI/fvw4Dh85it9++12FEkIIIacmAVkWpKLQoH491KxJRaE8kDKUspQylbIlhBBCTmUCUhakRYFKQvkjZSplSwghhJzKBKQsSNcDqRgoW0IIIac6ASkLtCpUHJQtIYSQUx2+DUGAuHQsW78R6zKSVYAD6pplaXEqoOJJyhB5Wp6OPurcJ+WVt6RMrJNyMB/m5xty8hWPZGSIsIwkdWpGph1IWSoNLmU1sNVLn7Rckwz0+/23uUy4PcIfsg2dzDZbkjhMXG5qL27lLYGSkZ97Nbmuz8VEf8VU9eGzzspB3ieFishnOfRP323N1Fe0vDvUla+6Ma5P8RF/EimzstC45ZWI7uQ92jULVTE2GrcS8a3QWJ1K7PeaD0s6ja/GjYOHY2hCLFpaEpBpdkBT86UyzfbN4SMXDoSi6d/7IXHYcPTvZc2fnr49b8bzLkLLEnH6YeTRV/ksZTgViYz1OeAkxXdDiPp9MpADYK89o9CuexIWqDCfZCXhurZRuC45SwWUHk0xGQTMEum08xyjkItwNFXX6ORbrpm1rxtSq4ISUBHKjGu9pCFByjAhTZ1XTZIyxiJm3wzVXmagIDIxQOVFTjCJwExvW3OWVTL6xwTSM4XSMqIbikR6CekqiJx8sj7ExuIQRHWxtYHLwrXxNSLaphDK8OINWJEq+tLMfET0/uvGmjIrC9ff+yzGpHqPZ19+G3PSh6KVijfoe+9zIv45DL1RBQjs95qPh/u3065pdUc6Mqc9g7tv7oUeCUmYMG0ext8RpcWhx3Bx7eOIb6ufSrQ0H7kdbdS5K6G98K9Zb2PyqKHo2yMWt4+YhCmzJ+L21ipeS9+eN+N5/8TQEnHyeAZ3ddfu9lm+oT30+FOTfBTkOzRijWRERxajuFidngxWvBTU5F8apGIyMCwHKW3jYR1Hs/BQd3uYlfQEMQGEtIGj2Mhpjt5vcjONSV4oSGLAD4nq6nfAT8pIRGjuKL8Tu3Zdfj78ds24rohCDmZTUfiLycLOfUBII+sSJCk6UoyvohbDGlvahgzHvh36gik9QyxeuqH/X2RdCM4NcfBTpPXshl4DhiF92S7UiOiHIYNVnMbN6NhC7vY/F5d3vFkPErzxgLhH3tfzBaw6KAK2zFHn3XB76lIxmd+Bgf2icPb372HU4N64afBjWLKzDlrdEI9YPYmg6DgoAdeGHULeK0PQt+8/MfiJD7D7/La4+Y54/YLXh+n5mbtZnBzAqokyb7dg7DIZOQ0jVF61Y8BErCo+gRPFq7B4oYxXGLIxHSNeV3GnKHl5YiCLSShh3uuTFouI/IVYJBq5HW1FLk2k2mE2DRqmN7MpVY/XzaYqzMG0KtNMTR3rucZietNcBSIdw2Wg3W8y82nYTL+uJkt9ZVaQHYAFwychCL9M/SwLRpnUqY65TLby+LEA+K4Tm+yVOVS3qohBKaQbUmW4p04CkaP1Guuq2V4vZvT7LNcrU6wnbyVk6j8/lrI7mu1LJ8u/Bqlk5GORP2VZtBup5E7OLFQBvunTRSyjNn5obeN+5S2wXGOtL60tSfkZfVE7/NSJJd7bBszXlLC8BJJPSx58tTkTfvIssfYVh3yVkXQxziKyk+mZulK5MXsDii0LjzhcGAYU5BnKZhZWbCwuaX04SZTPnoWizVi2cQeOiuRq1blcBQpu7ITLzz2ArVsO4NwWndBXBfulewc0P/sovl7+Cr4sEudFa5GxOAff7vwTIdH6JY788QcC+cRR3XNqiv8fFtnerp0XfbkA8zLnYck3P6G5FhI43e8ZhCtDfsSat1/BEpnXyozUXIsjEW3pOXHoEiUmU0+D9SI7+EAYJtYopOSGYaBt8I0Y1Al5WvwoLe2BotOlNlqo35OSg+LIxBKTvDlNeU3oIHvnF+lEr9HjnUyzYhUVvnGUJ41Z+eJ6H/5exDVGKPKRV9YVl3Z/MQq3qfOykL4GBaJMFrkndUJEsb4StJqyRXk2qmsccK0TMUCmxuzzulFmbtDuSU+Qv8UAJp6XIsMNmQYgx4hBI4HJKr22M1AUM7Zsg6qcEFJ1M7me1ktAb5vry09+tLJrFiKVRl4nDBQ6kBfZvsYiypyGdCP5ahtBk4bZuUBMvJG+UJ6EUuZXMZVtqrgQW10nNJlWGHInB6Lk6n24aIdJ+QhI3vKaNtiYYlyj16+lL0oF0+iL4tDamymvgYwRISLN6Dz1DGl5iRnpdYcGkk8pJ7MLURszdEXYEe16ITtPudYgWirLJmS+U6M2eNtSMG3bjtbfw3Chp4xyDNmHnem6i8Kz8JDWoBDr2LJgh1ix2awPJ4vglIUajdBh2HAMHfYQxsR3xPk/52P14k0qEujbMQLnHt6Cpbnf4ei5l6NdgCXseEEoauAYfj2iAgRF88YhOelJzMhTAaiJhh3ks/WjyXki6OBerNAjXVn+2VfYf+Ji9Bz3DsYl9cM1zQ5g6awpmDbrA0hbQsBcl4JB14Tgp9VvYupim6bgkY06br5GRZzKZOGhbJtfLCkBMU7mS9GJe4nVzyzTZL0geWEJk3zBTMOMr6et+fyNe7KSsEgEhTZWN8hnhVjTlNdMzrVr02bTrgPingTTqkzT5H11MM0nKAZmdaphGaRdBh05+YwQA1f+QjwUlMckDTKL5jJqZknTSrB4jzeH6ck+JohA6sRc1vQk93wHIMfi3JdMacjJsTggM7sdbU9M/gyT2V20l8lCmVRnGm750cou2oV58kyPFwqF+i1RbXmyOY1MqbCaV3nly4LkGMxCompLgbkWtDbpNAmbJlndTWGWvT+sk04g8pbXwKF+rX3Rob0Zim+AYwTM+dAWLN4J038+RR/sLRQwzzgj0MYVXy5V/Xp7u5XuIQ9ObUld469tS8XHO3YYRyIiVLzOVhSa9i1Iq09I/hqRf5vlwNivYK7jbYUoDrHvozo5BKcs1LoI0d2uR7duXdAmvAaObC/ANulW0NBdEEc3f4GF763BpqN10KLTDSrOHX3l749aaNxJPls/Ihqo4EBYlork59/BF0XnIrLHMDz58tvIeGEI2ge+O1JwDR5KuBYNjq7Ff6csQgmjgkc26riimYo4xZFar6kz2yctD9qGHN1SYO0Ufkzy9onZRJ/GYY7xJbVpoYX7GyTNE75t1VACe+cTk4yxmihQQV7MZVarVLNyU0aspkllllSjhIzTByFnc6kHf3Wi1a3uavBrpjXwI0fLalWg1VWp0c2tZoXIJ77yo5XdvV1o7ctwtRiHWLWGmFd55YruhvGsmsWxqJGoR8OSISYls4nf6hJxmmR1f7W2x0as1gPf09MU4VaTQQDy1q+xT36pcjOluS+W6K9yIlQ/AxwjnPKhLyACyadetohB5mds1CxK9n0BOvr19nZrwVdbCmCiLhbKoFHX3sM+juhKga54WC235rHO59j7FxGcsvDTGrza7wbc2q8P7h61BD82vxn3Drtej+vTAc3OBY5UayRW1o1wxhGgTtP2UHsAXdmw94D65caPWDtVPls/sr9XwQFS9Ml0jB7aF3F3P4X/fLgDZ7dJwGMjAlNmJFc9PAxdw4/iy4wXMd/J/eCRjToenaEiTnVMplO1MvDtOxUDWomOEeRua2MzTxBIE6LFLGleNdixmwT9Yi2zdcA2DZSlxZwPzQVhWlEo5UU38YqyuZrN3epEvYGgXDv+lI9SybEccB3ABX7z46KIejBcLZYjphQr9FJgciUZaBtijbeOxApYvi3iyYf5zR+fk7B6+yHSsFaIQ1N4QhCT6suv7twu/clb4jj5BfKGkofgx4hA8llgfmvEOHwq8QG4DQNpS0GwYIXcnyAVD6m8mPLjWazpilIgZT9ZlM+eBUHRl9+j+BegXuil2nlsp0jUOXEcdZrpK+tmdY7jRL1IXHmdFu1K0b4fcRR1EXaxd6nf/N4pmDN3OpKCtubH4OHX38ecScP1/Qk7VuG9Fybjo11CmblUVJJ2jR9aJ2FQTDiOfzUXk96r7BsVSqI1ZLHKnegxjzkgtexyXpFpWrWDSVhbEQasRKgd6CnubzF4kS4AMdB6/MrBoO90dtqA5L8Mej6kaVKuKJz82tKkra1SfL3iGmidqElK+vx7+fTBllaOOqWrKwMfctNWeAZ+8qOt+mzmbbUyNdDa10k04WqyKAs2656OMakohc98yL0/4j/pg/dtbTCv5gORt/Ouff+YJr+gx4hA8qkrQh5Xpl/k9SVdFJa6cmxLAvnc8lIisnagSLprMmwLAyN/8QmICnHYS1WeeSglwSkLZ9REfe0bArG4c/ytaHvuCfzwrdw1cAOiW9TBiW3zMcxYWT++FDtRHxFXKcuDG+/lYMPBamjS5WEkdBXpdx2AxM4tcM7hTVi9Ul1TZnKxfvtx1L78Otw/LFb7/kGX229Hx3Dg18Lv8I28xPjOQm35jzxVQ836sozGdxaicP8DvXDRia3Imb8Vl6hvKMjD8o0Ij2y8xyn/nQUDzecXiZgYIS1fewOUXzBmhNl0GoeJGdbNS6VCbbC0bKKLS8cIt3yUwD4Y6JvK3NBXe2KlZtt4VRZ0d4J506YgSW4s9F8G6T9H1EjNmuMdJGwy1TZD+cBPnfRJyzQpGdaJVMMykQYmx4hBJutEqevKiy43sxJkf56f/Kj3181KX5+0kbB8gsCpfcl0KmiDo756tL7qJvcaWCcHJ5QCa6pH7b4y743Rzd7mCdW/vPX2aN2ALBBt2b7BcYRJ4bTksxzGCP/51PdCWTZFCqxt3YxyAZjf+tLaramhOOZbf25wb02ZUfuUIkVZLMq1yp8Id1qolU0ZLx+CUxbqRiNR+4ZAEm5qUUMs0l/HlCmbRImugNAVsHPLCq8vf/NKbCkE6jXtiKtUkG+WYtqEDHx9Zlvc8ZhI/7FEtMJ6zE57AZ+pK4JheeozeGPVfjTqnaR9/+DRAW1Rc0cO3pj8tp5f4zsLPZuIk7roMFiW0fjOwlVofpEQW/Wm6P2U/v0E4zC+EaHhkY33OLW/s2BF66R+Bqf0BPnRIrMPeCzC84LpTKLjdxdphplNrHI3dmnMxPoGKHh8rZ2Q59d8rq/WtJ3xnrLIo7SbyATSZeAx86tD23kdQBnkhCfWTNZBQqyuzDL2Iw+3OlmwQ4gl1Rsu91t4VqLGRCrjtMkzMDkWzFyDaONZ2q71Mpr0pdxm7jPlTzxPWzEb+MtPybYzAi9ZNzhq1yjFUF2zbn0sCsug3ASEmHSus7UF7W2NAMz48g0Vc3vU7gtib4xUXGDenOdX3gKZfyFjy36A3oXWzc7FOViEkZ54ez6DHiMCyae4JkW6Tj3XyDeu1vhsh9JC53HpyWMEMNnWtu3yl2OB/EBWUC5WG9oYK7C/aaYpmeJvyb0avt9MOxmcERHZ+k/12yfhjUq1869ckV9DDDm+Deu2lMLcf90YvPPQ31FPnXqQ33N4YJo6kYSiafuLgB1fYOtf6E0o3FP1XBmEkFMJsaJfLibq7PKb8ORGS+31wlLtYSBlRm7uFcraXyXvU15ZKBOhzdHu0vqQTgQLR3cj7xv92wqnElQWCCEVjnz7Qn2zoDwUBioLJ5FyrruyEJCy0KhhKP91xAriTyH9PXupLBBCKhdUFk4vAlIW6tc7HzVr1lBnpDw5duw4Dhz8SZ0RQgghpx4BbXA8fOSotgIm5YuUqZQtIYQQcioTkLLw22+/Y/+Bg9oqmEpD8EgZSllKmUrZEkIIIacyAbkhCCGEEHL6Etx3FgghhBBS5aGyQAghhBBXqCwQQgghxBUqC4QQQghxhcoCIYQQQlyhskAIIYQQV6gsEEIIIcQVKguEEEIIcYXKAiGEEEJcobJACCGEEFcC+txzRItm6hchhBBCKgsF325Rv4KD/zYEIYQQQlyhG4IQQgghrlBZIIQQQogrVBYIIYQQ4gqVBUIIIYS4QmWBEEIIIa5QWSCEEEKIK1QWCCGEEOIKlQVCCCGEuEJlgRBCCCGuUFkghBBCiCtUFgghhBDiSsD/NsRZZ1VHndrnokaNGjjjDBVYSflTlPj48eM4fOQofvvtdxVKCCGEECcCsixIRaFB/XqoWbPyKwoSWQZZFlkmWTZCCCGE+CYgZUFaFKqCkmBHlkmWjRBCCCG+CUhZkK6HqkpVLhshhBBSHgSkLFRFq4JBVS4bIYQQUh7wbQhCCCGEuEJl4XQnLh3L1m/EOscjE0nqstOFPmm5oty5mBinAkhJTG0mIykZGfJ3RrKKDBCVxrK000XQUk5O7SoOE5eb+lxp5egzXSApw5Tu8nT0UeEG/uIJMRPQq5PhjULVLy+NW16JRg57A38uXI1vdpSM//3gNqzbUqTOdEKb/QN//3trnP/TV/j0k4+x1RotErkaN3Zvh7BjP4j4hVq6engrRIfXxMHvv/Dcoz2v5gH878vNMJIx0i9xv43CPfYHn6bIATw1HIvaxiNdBVUe5KA7FuHZUUiofJmvRMjJKRGY6UvOzvUglbDURgvRLiFNhZw+yEl5YKT8VYzclBg8lKUFa2hxmKHkossuauMoXJdsusgHbulq8o7agJTuSVggzq3P8R9PiJ0yWxauv/dZjEkteQzt4Rz/7MsZmPvvJFyr9I5Wd6Tj5UmjcfdtN+HWe0bjpWmvYEhrPU4i4zOnPYO7b+6FHglJmDBtHsbfEaVH9hgu0nwc8W31U4n2vEduRxvtLBQ9npyNN14ejSE39sI/7xD3T52Lccb9hJAgKEbhNvWTuCIn5YFhOUhpOwMFKsyDUM57ReZjlmeCzsJD2fkIiUnwa9FzTVcodP1jgNzJuiIgSc/MQXFkrLJA+IsnpCTBuSEOfoq0nt3Qy3SMeF3FSTzx8Rj13lZUaxKLIXdeI+byOzCwXxTO/v49jBog4h+Zg++qReDG4SPQXN5njh/cGzcNfgxLdtZBqxviEasl7IfoO3HbtWE4nDcJw+J6o+8gcf/u8xHVbxBuUZeQwJGrDo+50uKa0E3QHlO0KV4OZp57LKZV4x6r+bWkOdqcpjxcXCKaSXssYkKAiEHyWmWWTcrU79P+inBPPmymX7MJ1rhHnWrlkPFGGvbrFVYZyfKpCDtaXu1mYz0/hgwssvPnElHmfM/1prxpebKbtW3l08+993vzbeQpWclK5CNFPisREQhBTKoMk+mY8u5YD3p8qgyMTNSeoZfTaAf60zz5spTHlE8Na70ZefMp61OABckxaKdW7yW4LBwhxYXYqk410teIyT8MF7rVucA13bjGYrm0DzvNxomsD7GxOAThl4nf/uLtyLoptXuEVDVO0p6FInw5bQHW/wiEXdgK6N4Bzc8+iq+Xv4IvpQfgq2nI+vIAql3SCX2ixbk9vmgtMhbn4NudfyJExvvijz+gfY+x7jmoKf4cLtoEzfMg7v/g/zLw/pKv8ZOmjZBA8Zgn20ZpR0puGAbaJsuIQZ2Qp8WPQm5xJAaKgVwzOcuwFLliSSwxoEcMGglM1tNsJ1ZHRTFjPZOlPunopm7Lc0tMHoqsJFynPRso0O4xm2RFfqLX6OnYTL1G2rP2dUOq22AYIuKNNORKTpyP8Cg3+gRmlpEsc6iYLB0nMTUoR3UxzQZxXREVko9F0vQsBubUmH2YZaQ1c4O6yAE5iKe2wcYUda04tLKo+knPyxfF72SRWVJ0JIpzM6B5COT9g+B9lpZvq3ISEiPUc62ehExTpZzlSlaavWWYzV3lWA9itdxd1p8IzNdl5NvELupqhHiclh/VliwKnlBE9nnlPFksHaQOUlnp0zgM2LfDecIPBiclxIy/eEIcCE5ZqNEIHYYNx1DjuPkaFVGS0PaR+Nt5YgL/cQ+ah56PGjiGX4+oSMHy3WIwEVN8rbpAxwtCS8QXzRuH5KQnMSNPBYhrG3bwPruJSBsH92KFjFq2El8Xn8BFPV/Emy88jBv/3hwHl7yJaVPfxNLN8gISEGLStppJ5YpmoZgs28A81xXMNCYN3YwqZgXvPWICWSSCQhubbhAU575kmtDTMFtMJiFRXbVJLim+G0LExGL2eS9IfkmbPKJLvYoUE1umyQ+blIAY5GCyacLSTbDWSdWKWQYqr42a6qcyPTHRm2UkyzxZXBMR7aSAZGHFRm9ZJX26tBHlXeOdeM0DeXqSxRftRUyeveXEb5ajuDxBKjOqfrRVqllmyYiOLMbGFfIG/X5v3Qm0urIpMvkLfTy/IhB15TGNq7YU1liXk4Oc9TahTqoUPlb45YC9H9rxF09OX4JTFmpdhOhu16ObcVzRTEUozu+Ee+e+jzlzF+A/Y/+JC38twNI57+OiunXUBc7UPUfaBfxRC407eZ8d0UAFayzF80ljkfnFPpzb8p+4e9RUvDF7Iga1L7lRk7ggVyBytecxC8tDN0O7DmYBrFqKdlhnoAU79qlfcbhQLLiK99hTyMJOcUnpBzOruVVbzUlLgblMqUI5cTP9OpVHTWJaeg7xWnmMic7GghUbUOxRuOLQJSoEBXlqEpQTvMqfu3m9KcLFqtouR4icFHrMyWmQxgWP0pLUCRHFG6DpCup+3V3gPeSGOY8iJChZDxWJzTQuCQkXOfUt56qJ2hPi4mIqKyXbixVPvOYWUs8dJBqFciFpB10SpyXBKQs/rcGr/W7Arcbx6AwVofhlO/JyliInZzE+eHsCRg69H298BWzYe0Bd4Iy/eJ0fsXaq99nZ36tgg6KPMOupIbg1djBSX8vBrlptcdu/kgLb80BMiNWcMvuaj4p+48DfoBYUxXJjmL1M1t3kpaK0pmSL/1h3QeR55JmGBJkf5coo6bc343+joeaKUEqL5oLY+KElr7q7wHaYrSSnEhVhsv8LcVMoNTS3jqlefO1RsLOtUCijupLliL94SXq897kzRRtSLiTtOFXbB6lQKnbPwvE9+GLqFEyTR8Ziz2uORft+xFHURdjF3pV+30svAE6IwW+9c3zze6dgztzpSPLt6fDQ5ZEZ4topGKrtT9iO1fOew5SPdgJ1LkPrLtolJBDkoBLAZqvywOu/1S0IJU34usUhWCVCG6D9DZSlQEvPwYXh7o/WXRGyjNIFAWMPgRk1UczKj0Qvz/4IM7oFweIy0JAWA5MSoVkqpBVDuiDUvggNeX/lMTs7y1m3jlRanCZti/WnjGTtQJG935qVUn/xhDgQnLJwRk3U73Qlok1Hy8Yqzo33cvClGKiadHkYCV2vRJfbX8DN7c7Fr9+sRJZUKET8hoPVPPHRXQcgsXMLnHN4E1av1JNwY8X6H/Bb7RaIeeB+9JL5EvfHd/gb8Otu/O8bdRHxj/Jhx4wwmz/jMDEjeHNoxCDTijkuHSPkq1xqb4G+h8C6KbJP2khtr8FsP4OZ38kvPcO2cU6SjIyymlad0rOVxwlt70dkLEZEQe0h0OmTlmnaYKgrSM4Yr9mNtGxITMpIRIRln4HcYwFEjYgV4aZ9ET7utz6/7DjWg9sq2h9q/4VZcdLKqn5XSjQLk20Tp9xHkh2gBcEn0v1k7bdyH5BXKfUXT0hJglMW6kYj0fQtBXkY31lwZyleF4PS12e2xR2PPYtHB7RFzR1LMW382+qDSuL3hAxP/JjHEtEK6zE77QV8psX7YdloPP/6pzgQ3gf3y3yJ+6PO3o4Vr6djtrJukMBITxiFXJh9/GMRnhfsYCbN32sQbaSZ2g1FM01uALmq9pjh9cP8ARlnjMlvrLje7XVDcV33GWKiNvlg18ei0GVid0emJ2QUZkpPe0PBn1tDH7BDYF1FLtgB9VqiPPx8oEeaimfuM13v/GEduUcCIaZ9EQbi/hShSJjvT220JsgNjc71oG+M1dtRyddkA0G6Z/S3Zoy8Rufpb15UXuxtR6/v8nDxpSeoN2OUrGS7MLcjf/EWZDuj6+G0p8xfcCwvQpt1QNivX/j8uqL8MmPI8ZJffwwUmf6F2O56P7/geDKR79e7fQGQkECRbUkoen4VM0JIsFTsnoUAKNriW1GQ7PhmdZkVBYlMP5j7CSGnJpobIlj/PiEkIAJSFv70a3uovFTlshFSdbB/0VO5XAJ9Q4AQEhQBuSHq1zsfNWvWUGdVi2PHjuPAwZ/UGSGEEELsBGRZOHzkaJVcgcsyybIRQgghxDcBKQu//fY79h84qK3Cq4LSIMsgyyLLJMtGCCGEEN8E5IYghBBCyOnLX/42BCGEEEJObagsEEIIIcQVKguEEEIIcYXKAiGEEEJcobJACCGEEFeoLBBCCCHEFSoLhBBCCHGFygIhhBBCXKGyQAghhBBXqCwQQgghxJWAPvcc0aKZ+kUIIYSQykLBt1vUr+Dgvw1BCCGEEFfohiCEEEKIK1QWCCGEEOIKlQVCCCGEuEJlgRBCCCGuUFkghBBCiCtUFgghhBDiAvD/SQ5VERZxYIMAAAAASUVORK5CYII=)"
      ],
      "metadata": {
        "id": "jUDcRK_Pt6u4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Augmentation (Aumento de Dados)\n",
        "\n",
        "O ImageDataGenerator cria varia√ß√µes artificiais das imagens para:\n",
        "\n",
        "    Prevenir overfitting: Faz o modelo generalizar melhor\n",
        "\n",
        "    Aumentar dataset: Gera \"novas\" imagens a partir das existentes\n",
        "\n",
        "    Normaliza√ß√£o: Redimensiona valores dos pixels para 0-1 (rescale=1./255)\n",
        "\n",
        "T√©cnicas aplicadas:\n",
        "\n",
        "    Rota√ß√µes (20¬∞): ajuda o modelo a reconhecer objetos em diferentes √¢ngulos\n",
        "\n",
        "    Deslocamentos (20%): torna o modelo robusto a posi√ß√µes variadas\n",
        "\n",
        "    Flip horizontal: √∫til para objetos sim√©tricos como rostos\n",
        "\n",
        "2. Geradores de Dados\n",
        "\n",
        "Os geradores (flow_from_directory):\n",
        "\n",
        "    Leem imagens diretamente do disco: eficiente em mem√≥ria\n",
        "\n",
        "    Dividem automaticamente em treino/valida√ß√£o (80/20%)\n",
        "\n",
        "    Organiza√ß√£o esperada:\n",
        "\n",
        "Arquitetura CNN\n",
        "\n",
        "Modelo Sequencial com:\n",
        "\n",
        "    Camadas Convolucionais:\n",
        "\n",
        "        Conv2D: Extrai features locais (32 e 64 filtros)\n",
        "\n",
        "        MaxPooling2D: Reduz dimensionalidade mantendo features importantes\n",
        "\n",
        "    Camadas Densas:\n",
        "\n",
        "        Flatten: Prepara para camadas fully connected\n",
        "\n",
        "        Dense(128): Camada intermedi√°ria com 128 neur√¥nios\n",
        "\n",
        "        Dense(1): Sa√≠da bin√°ria (sigmoid para probabilidade 0-1)\n",
        "\n",
        "4. Compila√ß√£o do Modelo\n",
        "\n",
        "    Optimizer 'adam': Adapta taxa de aprendizado automaticamente\n",
        "\n",
        "    Binary crossentropy: Fun√ß√£o de perda ideal para 2 classes\n",
        "\n",
        "    Accuracy: M√©trica principal para avalia√ß√£o\n",
        "\n",
        "5. Treinamento\n",
        "\n",
        "    Epocas (EPOCHS): Passagens completas pelo dataset\n",
        "\n",
        "    Valida√ß√£o: Monitora desempenho em dados n√£o vistos\n",
        "\n",
        "    History: Armazena m√©tricas para visualiza√ß√£o posterior\n",
        "\n",
        "Fluxo Completo\n",
        "\n",
        "    Pr√©-processa e aumenta imagens automaticamente\n",
        "\n",
        "    Cria modelo CNN simples mas eficaz\n",
        "\n",
        "    Treina monitorando valida√ß√£o\n",
        "\n",
        "    Sa√≠da: modelo capaz de classificar novas imagens\n",
        "\n",
        "Este pipeline √© amplamente utilizado em problemas b√°sicos de classifica√ß√£o de imagens, sendo f√°cil de adaptar para diferentes casos!"
      ],
      "metadata": {
        "id": "_r95Mc5hwFtv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importa a arquitetura MobileNetV2 pr√©-treinada\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "\n",
        "# Carrega o modelo base MobileNetV2 com pesos pr√©-treinados no ImageNet\n",
        "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3)) # Usa pesos treinados no ImageNet(Remove a √∫ltima camada (classifica√ß√£o original e define o formato de entrada das imagens)\n",
        "base_model.trainable = False # Os pesos n√£o ser√£o atualizados durante o treino\n",
        "\n",
        "# Cria um novo modelo sequencial\n",
        "model = Sequential([\n",
        "    base_model,  # Extrai features das imagens\n",
        "    Flatten(), # Transforma os features em vetor\n",
        "    Dense(128, activation='relu'), # Adiciona capacidade de aprendizado\n",
        "    Dense(1, activation='sigmoid') # Sa√≠da entre 0 e 1 (probabilidade)\n",
        "])"
      ],
      "metadata": {
        "id": "W0UA12crLWKr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explica√ß√£o Detalhada\n",
        "1. MobileNetV2 Pr√©-treinado\n",
        "\n",
        "    O que √©? Uma rede neural eficiente projetada para dispositivos m√≥veis\n",
        "\n",
        "    Pr√©-treinamento: J√° aprendeu a extrair features de 1.4 milh√£o de imagens (ImageNet)\n",
        "\n",
        "    Par√¢metros:\n",
        "\n",
        "        weights='imagenet': Carrega pesos otimizados\n",
        "\n",
        "        include_top=False: Remove as camadas finais de classifica√ß√£o\n",
        "\n",
        "        input_shape=(224,224,3): Espera imagens coloridas 224x224 pixels\n",
        "\n",
        "2. Congelamento do Modelo Base\n",
        "\n",
        "    base_model.trainable = False:\n",
        "\n",
        "        Mant√©m os pesos originais inalterados\n",
        "\n",
        "        Acelera o treinamento (s√≥ treina novas camadas adicionadas)\n",
        "\n",
        "        Evita \"destruir\" os padr√µes j√° aprendidos\n",
        "\n",
        "3. Arquitetura Personalizada\n",
        "\n",
        "    Extra√ß√£o de Features:\n",
        "\n",
        "        MobileNetV2 processa a imagem e extrai caracter√≠sticas complexas\n",
        "\n",
        "    Flatten():\n",
        "\n",
        "        Transforma a sa√≠da 3D (7x7x1280) em 1D (62720 valores)\n",
        "\n",
        "        Prepara para camadas densas\n",
        "\n",
        "    Camada Dense (128 neur√¥nios):\n",
        "\n",
        "        Aprende combina√ß√µes n√£o-lineares dos features\n",
        "\n",
        "        Fun√ß√£o ReLU (Rectified Linear Unit) para ativa√ß√£o\n",
        "\n",
        "    Camada de Sa√≠da:\n",
        "\n",
        "        1 neur√¥nio com sigmoid (classifica√ß√£o bin√°ria)\n",
        "\n",
        "        Sa√≠da entre 0-1 (probabilidade da classe positiva)\n",
        "\n",
        "Vantagens desta Abordagem\n",
        "\n",
        "    Efici√™ncia:\n",
        "\n",
        "        Reutiliza conhecimento pr√©-treinado\n",
        "\n",
        "        Requer menos dados para treinamento\n",
        "\n",
        "    Desempenho:\n",
        "\n",
        "        MobileNetV2 √© otimizado para velocidade\n",
        "\n",
        "        Boa acur√°cia mesmo com poucos dados\n",
        "\n",
        "    Flexibilidade:\n",
        "\n",
        "        F√°cil adapta√ß√£o para diferentes problemas\n",
        "\n",
        "        Pode adicionar mais camadas se necess√°rio\n",
        "\n",
        "Quando Usar?\n",
        "\n",
        "    Problemas com datasets pequenos/m√©dios\n",
        "\n",
        "    Quando se precisa de bom desempenho com baixo poder computacional\n",
        "\n",
        "    Para classifica√ß√£o bin√°ria ou multi-classe (ajustando a camada final)\n",
        "\n",
        "Fluxo de Processamento"
      ],
      "metadata": {
        "id": "FVi9Z0UKxIvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "\n",
        "# Carregar o modelo treinado\n",
        "model = load_model('modelo_classificacao_racial.h5')  # Ou use o caminho correto\n",
        "\n",
        "# Fun√ß√£o para processar imagem da internet\n",
        "  \"\"\"Classifica uma imagem obtida por URL usando o modelo treinado\n",
        "\n",
        "    Args:\n",
        "        img_url (str): URL da imagem a ser classificada\n",
        "\n",
        "    Returns:\n",
        "        dict or None: Resultados da classifica√ß√£o ou None em caso de erro\n",
        "    \"\"\"\n",
        "def test_image_from_url(img_url):\n",
        "    try:\n",
        "        # Baixar a imagem\n",
        "        response = requests.get(img_url) # Timeout de 10 segundos\n",
        "        img = Image.open(BytesIO(response.content)) # Verifica erros HTTP\n",
        "\n",
        "        # Converte para RGB caso seja PNG, RGBA, etc.\n",
        "        if img.mode != 'RGB':\n",
        "            img = img.convert('RGB')\n",
        "\n",
        "        # Mostrar a imagem original\n",
        "        plt.figure(figsize=(5, 5))\n",
        "        plt.imshow(img)\n",
        "        plt.axis('off')\n",
        "        plt.title('Imagem Original')\n",
        "        plt.show()\n",
        "\n",
        "        # Pr√©-processamento\n",
        "        img = img.resize((224, 224)) # Redimensiona para o tamanho esperado pelo modelo\n",
        "        img_array = image.img_to_array(img) # Converte para array numpy\n",
        "        img_array = np.expand_dims(img_array, axis=0) # Adiciona dimens√£o do batch\n",
        "        img_array /= 255.0  # Normaliza pixels para [0,1]\n",
        "\n",
        "        # Fazer a predi√ß√£o\n",
        "        prediction = model.predict(img_array) # Suprime logs\n",
        "        prob_branca = 1 - prediction[0][0] # Probabilidade da classe 'preta'\n",
        "        prob_preta = prediction[0][0] # Probabilidade complementar\n",
        "\n",
        "        # Determinar a classe\n",
        "        if prob_branca > prob_preta:\n",
        "            classe = \"Branca\"\n",
        "            confidence = prob_branca\n",
        "        else:\n",
        "            classe = \"Preta\"\n",
        "            confidence = prob_preta\n",
        "\n",
        "        # Mostrar resultados\n",
        "        print(\"\\nResultado da Classifica√ß√£o:\")\n",
        "        print(f\"Classe Predita: {classe}\")\n",
        "        print(f\"Confian√ßa: {confidence:.2%}\")\n",
        "        print(f\"Probabilidade Branca: {prob_branca:.2%}\")\n",
        "        print(f\"Probabilidade Preta: {prob_preta:.2%}\")\n",
        "\n",
        "        return {\n",
        "            'class': classe,\n",
        "            'confidence': float(confidence),\n",
        "            'probabilities': {\n",
        "                'branca': float(prob_branca),\n",
        "                'preta': float(prob_preta)\n",
        "            }\n",
        "        }\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Erro ao processar a imagem: {e}\")\n",
        "        return None\n",
        "\n",
        "# Exemplos de URLs para testar (substitua por URLs reais)\n",
        "test_urls = [\n",
        "    \"https://www.minhavidamagnolia.com.br/wp-content/uploads/2024/07/Branca-Rubas-apresenta-o-Inspira-Mulher-Business-Club.png\",  # URL de mulher branca\n",
        "    \"https://paesadvogados.com.br/wp-content/uploads/2022/05/pardo.jpg\",   # URL de mulher preta\n",
        "\n",
        "]\n",
        "\n",
        "# Testar cada URL\n",
        "for url in test_urls:\n",
        "    print(f\"\\nTestando imagem: {url}\")\n",
        "    result = test_image_from_url(url)\n",
        "    if result:\n",
        "        print(f\"Resultado: {result['class']} (Confian√ßa: {result['confidence']:.2%})\")"
      ],
      "metadata": {
        "id": "3FO1860yLu6-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fluxo da Fun√ß√£o\n",
        "\n",
        "    Download Seguro: Adicionado timeout e tratamento de erros HTTP\n",
        "\n",
        "    Convers√£o Robusta: Garante que todas as imagens estejam no formato RGB\n",
        "\n",
        "    Visualiza√ß√£o: Mostra a imagem antes da classifica√ß√£o\n",
        "\n",
        "    Pr√©-processamento:\n",
        "\n",
        "        Redimensionamento para 224x224px\n",
        "\n",
        "        Normaliza√ß√£o dos valores dos pixels\n",
        "\n",
        "    Predi√ß√£o:\n",
        "\n",
        "        Usa o modelo treinado\n",
        "\n",
        "        Calcula probabilidades para ambas as classes\n",
        "\n",
        "    Resultados:\n",
        "\n",
        "        Exibe informa√ß√µes formatadas\n",
        "\n",
        "        Retorna dados estruturados\n",
        "\n",
        "2. Melhorias Implementadas\n",
        "\n",
        "    Tratamento de Erros: Espec√≠fico para problemas de download e gen√©rico para outros erros\n",
        "\n",
        "    Visualiza√ß√£o: Tamanho maior e t√≠tulo descritivo\n",
        "\n",
        "    Sa√≠da Formatada: Usa emojis e formata√ß√£o para melhor legibilidade\n",
        "\n",
        "    Controle de Logs: Suprime mensagens do TensorFlow (verbose=0)\n",
        "\n",
        "    Progresso: Mostra contagem de testes (ex: \"Teste 1/2\")\n",
        "\n",
        "Boas Pr√°ticas Inclu√≠das\n",
        "\n",
        "    Docstring: Documenta√ß√£o da fun√ß√£o\n",
        "\n",
        "    Timeout: Evita travamento em URLs problem√°ticas\n",
        "\n",
        "    Tipagem Impl√≠cita: Nomes de vari√°veis descritivos\n",
        "\n",
        "    Resili√™ncia: Convers√£o obrigat√≥ria para RGB\n",
        "\n",
        "    Visualiza√ß√£o: Ajuda no debug e an√°lise"
      ],
      "metadata": {
        "id": "R1M8VQUMyERK"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DdNbgzF3yIgK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}